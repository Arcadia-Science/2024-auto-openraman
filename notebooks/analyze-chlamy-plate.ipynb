{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoOpenRaman acquisition and analysis\n",
    "\n",
    "This notebook is a basic analysis of multi-position data generated using AutoOpenRaman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import ramanspy as rp\n",
    "\n",
    "\n",
    "def parse_autoopenraman_csv(csv_filename):\n",
    "    data = pd.read_csv(csv_filename)\n",
    "\n",
    "    # parse and load data into spectral objects\n",
    "    if \"Wavenumber (cm-1)\" in data.columns:\n",
    "        spectral_axis = data[\"Wavenumber (cm-1)\"]\n",
    "    elif \"Pixel\" in data.columns:\n",
    "        spectral_axis = data[\"Pixel\"]\n",
    "    else:\n",
    "        raise ValueError(\"No valid spectral axis found in the CSV file.\")\n",
    "\n",
    "    spectral_data = data[\"Intensity\"]\n",
    "\n",
    "    raman_spectrum = rp.Spectrum(spectral_data, spectral_axis)\n",
    "\n",
    "    return raman_spectrum\n",
    "\n",
    "\n",
    "def get_wavenumber_axis(csv_filename):\n",
    "    return parse_autoopenraman_csv(csv_filename).spectral_axis\n",
    "\n",
    "\n",
    "def get_background_spectrum(bg_csv_filename):\n",
    "    # Adjust the background spectrum to match the wavenumber axis of the spectrum\n",
    "    bg_spectrum = parse_autoopenraman_csv(bg_csv_filename)\n",
    "\n",
    "    first_file = next(\n",
    "        file for file in pathlib.Path(well_plate_data_dir).iterdir() if file.suffix == \".csv\"\n",
    "    )\n",
    "\n",
    "    wavenumber_axis = get_wavenumber_axis(first_file)\n",
    "    adjusted_background = rp.Spectrum(bg_spectrum.spectral_data, wavenumber_axis)\n",
    "    return adjusted_background\n",
    "\n",
    "\n",
    "# Unzip the zip file to the specified directory\n",
    "\n",
    "zip_file = pathlib.Path(\"data/automated-chlamy-data.zip\")\n",
    "data_dir = pathlib.Path(\"data/automated-chlamy-data\")\n",
    "well_plate_data_dir = data_dir / \"chlamyparentplate1\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(data_dir)\n",
    "\n",
    "dark_control = data_dir / \"chlamy-dark.csv\"\n",
    "\n",
    "dark_control_spectrum = get_background_spectrum(dark_control)\n",
    "\n",
    "rp_pipeline = rp.preprocessing.Pipeline(\n",
    "    [\n",
    "        rp.preprocessing.misc.BackgroundSubtractor(background=dark_control_spectrum),\n",
    "        rp.preprocessing.misc.Cropper(region=(900, 1900)),\n",
    "        rp.preprocessing.despike.WhitakerHayes(),\n",
    "        rp.preprocessing.denoise.SavGol(window_length=5, polyorder=3),\n",
    "        rp.preprocessing.baseline.ASPLS(lam=1e5),\n",
    "        rp.preprocessing.normalise.MinMax(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Cycle through files in the mapping directory\n",
    "for file in pathlib.Path(well_plate_data_dir).iterdir():\n",
    "    if file.suffix == \".csv\":\n",
    "        # Parse the filename\n",
    "\n",
    "        parts = file.name.split(\"-\")\n",
    "        well = parts[0]\n",
    "        site = parts[1].split(\"_\")[1]\n",
    "\n",
    "        # Parse the spectrum from the file\n",
    "        spectrum = parse_autoopenraman_csv(well_plate_data_dir / file.name)\n",
    "\n",
    "        # Process the spectrum\n",
    "        processed_spectrum = rp_pipeline.apply(spectrum)\n",
    "        # Append the data to the list\n",
    "        data.append({\"well\": well, \"site\": site, \"raw\": spectrum, \"processed\": processed_spectrum})\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot representative spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcadia_pycolor as apc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "apc.mpl.setup()\n",
    "\n",
    "random_spectra = df.sample(10)[\"processed\"].to_list()\n",
    "all_spectra_container = rp.SpectralContainer.from_stack(df[\"processed\"].to_list())\n",
    "\n",
    "plt.figure(figsize=(6, 8))\n",
    "rp.plot.spectra(random_spectra, plot_type=\"single stacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform NMF on all collected spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = rp.analysis.decompose.NMF(n_components=5, max_iter=5000)\n",
    "\n",
    "\n",
    "projections, components = nmf.apply(all_spectra_container)\n",
    "components = sorted(components, key=lambda x: x.max(), reverse=True)\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax = rp.plot.spectra(\n",
    "    components,\n",
    "    all_spectra_container.spectral_axis,\n",
    "    plot_type=\"single stacked\",\n",
    "    label=[f\"Component {i + 1}\" for i in range(len(components))],\n",
    "    title=\"NMF components\",\n",
    ")\n",
    "ax.legend_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the temporary data directory\n",
    "shutil.rmtree(data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoopenraman-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
